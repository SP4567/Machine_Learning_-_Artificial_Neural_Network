# -*- coding: utf-8 -*-
"""PowerCo_company_customer_churn_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sa0U5w9umwGCavDbahkLzhQKw1g0mQQl
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

client = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/client_data (1).csv')
price = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/price_data (1).csv')

client.info()

price.info()

sns.countplot(x = 'churn', data = client)

plt.figure(figsize = (30,5))
sns.countplot(x = 'channel_sales', data = client)

client['channel_sales'].value_counts()

plt.figure(figsize = (30,5))
sns.countplot(x = 'origin_up', data = client)

client['origin_up'].value_counts()

client.describe().transpose()

price.describe()

churned_cust = client[client['churn'] == 1]

churned_cust.head(5)

not_churned_cust = client[client['churn'] == 0]

not_churned_cust.head(5)

print(client['churn'].value_counts())

x = client['cons_12m']
y = client['forecast_cons_12m']
plt.xlabel('cons_12m')
plt.ylabel('forecast_cons_12m')
plt.title('Graph between cons_12m & forecast_cons_12m')
plt.scatter(x,y)

x = client['cons_12m']
y = client['cons_gas_12m']
plt.xlabel('cons_12m')
plt.ylabel('cons_gas_12m')
plt.title('Graph between cons_12m_&_cons_gas_12m')
plt.scatter(x,y)

plt.figure(figsize = (20,7))
sns.heatmap(client.corr(), annot = True)

sns.heatmap(price.corr(), annot = True)

client.corr()['churn']

sns.countplot(x = 'has_gas', data = client)

client['has_gas'].value_counts()

x = client['cons_12m']
y = client['imp_cons']
plt.xlabel('cons_12m')
plt.ylabel('imp_cons')
plt.title('Graph between cons_12m & imp_cons')
plt.scatter(x,y)

x = client['forecast_price_energy_off_peak']
y = client['forecast_price_energy_peak']
plt.xlabel('forecast_price_energy_off_peak')
plt.ylabel('forecast_price_energy_peak')
plt.title('Graph between forecast_price_energy_off_peak & forecast_price_energy_peak')
plt.plot(x,y, '^')

x = client['margin_gross_pow_ele']
y = client['margin_net_pow_ele']
plt.xlabel('Gross')
plt.ylabel('Net')
plt.title('Graph between Gross and Net pow ele')
sns.scatterplot(data=client, x='margin_gross_pow_ele', y='margin_net_pow_ele')

sns.boxplot(x = 'net_margin',data = client)

sns.boxplot(x = 'nb_prod_act', data = client)

price.info()

price.head(5)

monthly_price_by_id = price.groupby(['id', 'price_date']).agg({'price_off_peak_var': 'mean', 'price_off_peak_fix': 'mean'}).reset_index()
jan_prices = monthly_price_by_id.groupby('id').first().reset_index()
dec_prices = monthly_price_by_id.groupby('id').last().reset_index()
diff = pd.merge(dec_prices.rename(columns={'price_off_peak_var': 'dec_1', 'price_off_peak_fix': 'dec_2'}), jan_prices.drop(columns='price_date'), on='id')
diff['offpeak_diff_dec_january_energy'] = diff['dec_1'] - diff['price_off_peak_var']
diff['offpeak_diff_dec_january_power'] = diff['dec_2'] - diff['price_off_peak_fix']
diff = diff[['id', 'offpeak_diff_dec_january_energy','offpeak_diff_dec_january_power']]
diff.head()

sns.scatterplot(x = 'offpeak_diff_dec_january_energy', y = 'offpeak_diff_dec_january_power', data = diff)

client.info()

client['forecast_price_energy_peak']

client['forecast_price_energy_off_peak']

client['Diff_cons_12m_&_forecast_cons_12m'] = client['forecast_cons_12m'] - client['cons_12m']
client['Diff_forecast_price_energy_off_peak_&_forecast_price_energy_peak'] = client['forecast_price_energy_off_peak'] - client['forecast_price_energy_peak']

client.info()

client['date_activ'] = pd.to_datetime(client['date_activ'], format = '%Y-%m-%d')
client['date_end'] = pd.to_datetime(client['date_end'], format = '%Y-%m-%d')
client['date_modif_prod'] = pd.to_datetime(client['date_modif_prod'], format = '%Y-%m-%d')
client['date_renewal'] = pd.to_datetime(client['date_renewal'], format = '%Y-%m-%d')
client.head(5)

df = pd.merge(client, diff, on = 'id')

df.head(5)

df.info()

df.columns

selected_features = ['cons_12m', 'cons_gas_12m', 'cons_last_month','forecast_cons_12m', 'forecast_cons_year', 'forecast_discount_energy',
       'forecast_meter_rent_12m', 'forecast_price_energy_off_peak',
       'forecast_price_energy_peak', 'forecast_price_pow_off_peak',
       'imp_cons', 'margin_gross_pow_ele', 'margin_net_pow_ele', 'nb_prod_act',
       'net_margin', 'num_years_antig','pow_max','Diff_cons_12m_&_forecast_cons_12m',
       'Diff_forecast_price_energy_off_peak_&_forecast_price_energy_peak',
       'offpeak_diff_dec_january_energy', 'offpeak_diff_dec_january_power']

X = df[selected_features]
y = df['churn']

print(X.shape)
print(y.shape)

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)

X_test = scaler.fit_transform(X_test)

print(X_train)
print(X_test)

y_train

y_test

model1 = LogisticRegression()
model1.fit(X_train,y_train)
print("Training score:", model1.score(X_train,y_train))
print("Testing score:", model1.score(X_test,y_test))

model2 = KNeighborsClassifier()
model2.fit(X_train,y_train)
print("Training score:", model2.score(X_train,y_train))
print("Testing score:", model2.score(X_test,y_test))

model3 = RandomForestClassifier()
model3.fit(X_train,y_train)
print("Training score:", model3.score(X_train,y_train))
print("Testing score:", model3.score(X_test,y_test))

y_predict = model1.predict(X_test)

y_predict

X_test[1]

y_train_predict = model1.predict(X_train)

y_train_predict

y_predict = (y_predict > 0.5)

y_train_predict = (y_train_predict > 0.5)

from sklearn.metrics import confusion_matrix, classification_report

cm = confusion_matrix(y_train_predict,y_train)
cm2 = confusion_matrix(y_predict, y_test)

sns.heatmap(cm,annot = True)

sns.heatmap(cm2, annot = True)

prediction_1 = model1.predict(X_test[[4]])

prediction_1

print("Predicted churn class([0]: indicates not churned, [1]:indicates chruned):", prediction_1)

y_predicted_2 = model2.predict(X_test)

y_train_predicted_2 = model2.predict(X_train)

y_predicted_2 = (y_predicted_2 > 0.5)
y_train_predicted_2 = (y_train_predicted_2 > 0.5)

cm3 = confusion_matrix(y_train_predicted_2,y_train)
cm4 = confusion_matrix(y_predicted_2,y_test)

sns.heatmap(cm3, annot = True)

sns.heatmap(cm4, annot = True)

prediction_2 = model2.predict(X_test[[2500]])

print("Predicted churn class([0]: indicates not churned, [1]:indicates chruned):",prediction_2)

model4 = Sequential([Dense(64, activation = 'relu',input_shape = (21,)),
                     Dense(32, activation = 'relu'),
                     Dense(32, activation = 'relu'),
                     Dense(1,activation = 'sigmoid')])
model4.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

from tensorflow.keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor = 'val_loss', patience = 2)
epochs_hist = model4.fit(X_train,y_train, epochs = 25, validation_data = (X_test,y_test), callbacks = [early_stop])

epochs_hist.history.keys()

e1 = epochs_hist.history['loss']
e2 = epochs_hist.history['accuracy']
e3 = epochs_hist.history['val_loss']
e4 = epochs_hist.history['val_accuracy']
plt.plot(e1)
plt.plot(e2)
plt.plot(e3)
plt.plot(e4)
plt.xlabel('epochs')
plt.ylabel('loss,accuracy,val_loss,val_accuracy')
plt.legend(['loss', 'accuracy', 'val_loss', 'val_accuracy'])

y_predict4 = model4.predict(X_test)
y_train_predict4 = model4.predict(X_train)

y_predict4 = (y_predict > 0.5)
y_train_predict4 = (y_train_predict4 > 0.5)

cm5 = confusion_matrix(y_train_predict4,y_train)
cm6 = confusion_matrix(y_predict4, y_test)

sns.heatmap(cm5, annot = True)

sns.heatmap(cm6, annot = True)

prediction_4 = model4.predict(X_test[[1599]])

print("Predicted churn class([0]: indicates not churned, [1]:indicates churned):",prediction_5)
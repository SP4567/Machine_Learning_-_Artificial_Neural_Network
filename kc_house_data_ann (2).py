# -*- coding: utf-8 -*-
"""kc_house_data_ann.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MZn05MtB3jTYH6dKhegqgwvFbfijlmDM
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import seaborn as sns
from sklearn.linear_model import LinearRegression
from google.colab import drive
drive.mount('/content/drive/')

kc = pd.read_csv('/content/kc_house_data.csv')

kc.head(10)

kc.info()

kc.describe()

x = kc['sqft_living15']
y = kc['price']
plt.scatter(x,y)
plt.xlabel('sqft_liv')
plt.ylabel('price of the house')
plt.title('graph between sqft living and price of the house')

x_numerical = kc[['id','price','bedrooms','bathrooms','sqft_living','sqft_lot', 'floors',	'waterfront', 'view', 'condition',	'grade',	'sqft_above',	'sqft_basement', 'yr_built',	'yr_renovated',	'zipcode',	'lat',	'long',	'sqft_living15',	'sqft_lot15']]

f, ax = plt.subplots(figsize = (20,20))
sns.heatmap(x_numerical.corr(), annot = True)

sns.pairplot(x_numerical)

selected_features = {"bedrooms", "bathrooms", "sqft_living", "sqft_above", "sqft_lot",	"floors", "sqft_basement", "yr_renovated", "condition", "zipcode", "lat", "long", "view", "waterfront", "sqft_living15",	"sqft_lot15", "yr_built"}

X = kc[selected_features]

X

y

X.shape,y.shape

from sklearn.preprocessing import MinMaxScaler
Scaler = MinMaxScaler()
X_scaled = Scaler.fit_transform(X)

X_scaled

X_scaled.shape

y = y.values.reshape(-1,1)

y

y_scaled = Scaler.fit_transform(y)

y_scaled

y_scaled.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size = 0.2)

X_train.shape

X_test.shape

y_train.shape

y_test.shape

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(units = 100, activation = 'sigmoid', input_shape = (17,)))
model.add(tf.keras.layers.Dense(units = 100, activation = 'sigmoid'))
model.add(tf.keras.layers.Dense(units = 100, activation = 'sigmoid'))
model.add(tf.keras.layers.Dense(units = 1, activation  = 'linear'))

model.summary()

model.compile(optimizer = 'Adam', loss = 'mean_squared_error' )

epoch_hist = model.fit(X_scaled, y_scaled, epochs = 25, batch_size = 10, validation_split = 0.2)

epoch_hist.history.keys()

eh = epoch_hist.history['loss']
eh2 = epoch_hist.history['val_loss']
plt.plot(eh)
plt.plot(eh2)
plt.title("Loss during training the model")
plt.xlabel('epochs')
plt.ylabel('Training and validation loss during the training')

y_predict = model.predict(X_test)
  y_predict

plt.plot(y_test,y_predict, '^', color = 'r')
plt.xlabel('y_test')
plt.ylabel('y_predict')

y_predict_original = Scaler.inverse_transform(y_predict)
y_test_original = Scaler.inverse_transform(y_test)
plt.plot(y_test_original,y_predict_original,'^',color = 'b')
plt.xlabel('model_predictions')
plt.ylabel('true_values')

k = X_test.shape
k
n = len(X_test)
print('\n')
n

from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
from math import sqrt
RMSE = float(format(np.sqrt(mean_squared_error(y_test_original,y_predict_original)), '0.3f'))
print(RMSE)

MSE = mean_squared_error(y_test_original,y_predict_original)
print(MSE)

MAE = mean_absolute_error(y_test_original,y_predict_original)
print(MAE)

r2 = r2_score(y_test_original,y_predict_original)
print(r2)


# -*- coding: utf-8 -*-
"""weather_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ft4aVgwDAN_8lZhklNW-dUVV0GISlyE8
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

w = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/seattle-weather.csv')

w.info()

w = w.drop(labels = {'date'}, axis = 1)

w.info()

sns.countplot(x = 'weather', data = w, palette = 'deep')

sns.pairplot(w)

sns.pairplot(w, hue = 'weather')

w.columns

selected_features = {'precipitation', 'temp_max', 'temp_min', 'wind'}

w['weather'] = w['weather'].replace({'drizzle': 1, 'rain' : 2, 'sun' : 3, 'snow' : 4, 'fog' : 5 })

X = w[selected_features]
y = w['weather']

w.head(5)

Scaler = StandardScaler()
X_scaled = Scaler.fit_transform(X)

y

y_norm = pd.get_dummies(y)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_norm, test_size = 0.2)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.neighbors import KNeighborsClassifier
model1 = KNeighborsClassifier()
model1.fit(X_train,y_train)
print("Training_Score:",model1.score(X_train, y_train)*100)
print("Testing_score :",model1.score(X_test, y_test)*100)

#from sklearn.naive_bayes import GaussianNB
#model2 = GaussianNB()
#model2.fit(X_train,y_train)
#model2.score(X_test,y_test)

#from sklearn.linear_model import LogisticRegression
#model3 = LogisticRegression()
#model3.fit(X_train,y_train)
#model3.score(X_test,y_test)

from sklearn.ensemble import RandomForestClassifier
model4 = RandomForestClassifier()
model4.fit(X_train,y_train)
print("Training_Score:",model4.score(X_train, y_train)*100)
print("Testing_score :",model4.score(X_test, y_test)*100)

from sklearn.tree import DecisionTreeClassifier
model5 = DecisionTreeClassifier()
model5.fit(X_train, y_train)
print("Training_Score:",model5.score(X_train, y_train)*100)
print("Testing_score :",model5.score(X_test, y_test)*100)

#ANN = tf.keras.models.Sequential()
#ANN.add(tf.keras.layers.Dense(units = 100, activation = 'relu', input_shape = (4, )))
#ANN.add(tf.keras.layers.Dense(units = 100, activation = 'relu'))
#ANN.add(tf.keras.layers.Dense(units = 100, activation = 'relu'))
#ANN.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))

#ANN.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = 'accuracy')

#epochs_hist = ANN.fit(X_train, y_train, epochs=50, batch_size=125)

y_predict = model1.predict(X_test)

y_predict

sns.scatterplot(y_predict)

plt.plot(y_predict)
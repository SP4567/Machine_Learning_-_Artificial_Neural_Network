# -*- coding: utf-8 -*-
"""Amazon_Sales_Data_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pIvg3tsptQFtVAKM0fGTtzIA_dvcL6C6
"""

!pip install mplcyberpunk

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import mplcyberpunk

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Amazon Sales data.csv")

df.head(10)

df.info()

df.describe()

sns.countplot(x = 'Sales Channel', data = df)
mplcyberpunk.add_glow_effects()

sns.countplot(x = 'Order Priority', data = df)
mplcyberpunk.add_glow_effects()

sns.scatterplot(x = 'Unit Price', y = 'Unit Cost', data = df)

sns.scatterplot(x = 'Total Cost', y = 'Total Revenue', data = df)

sns.scatterplot(x = 'Total Cost', y = 'Total Profit', data = df)

print("Total revenue generated: ", df['Total Revenue'].sum())

print("Total Cost: ", df['Total Cost'].sum())

print("Total profit generated: ", df['Total Profit'].sum())

print("Max profit:", df['Total Profit'].max())

print("Minimum profit:", df['Total Profit'].min())

df['Profit Margin'] = (df['Total Profit']/df['Total Revenue'])*100

df.head(10)

df['Average Revenue per Unit'] = df['Total Revenue']/df['Units Sold']

df.head(10)

plt.figure(figsize = (20,10))
sns.countplot(x = 'Item Type', data = df, hue = 'Order Priority')

plt.figure(figsize = (19,10))
sns.barplot(x = 'Region', y = 'Total Revenue', data = df)

plt.figure(figsize = (19,10))
sns.boxplot(x = 'Region', y = 'Total Profit', data = df)

df['Sales Channel'].value_counts()

df['Region'].value_counts()

df['Country'].value_counts()

df.columns

new_r = pd.get_dummies(df['Region'], dtype = int)
region = pd.DataFrame(new_r)
new_c = pd.get_dummies(df['Country'], dtype = int)
country = pd.DataFrame(new_c)

region = region.replace({'True':1, 'False':0})

region

country

new_Channel = pd.get_dummies(df['Sales Channel'], dtype = int)
Channel = pd.DataFrame(new_Channel)

Channel.head(5)

new_item = pd.get_dummies(df['Item Type'], dtype = int)
Item = pd.DataFrame(new_item)

Item

new_Priority = pd.get_dummies(df['Order Priority'], dtype = int)
Priority = pd.DataFrame(new_Priority)

Priority

new_Date = pd.get_dummies(df['Ship Date'], dtype = int)
Date = pd.DataFrame(new_Date)
new_Date1 = pd.get_dummies(df['Order Date'], dtype = int)
Date1 = pd.DataFrame(new_Date1)

Date

Date1

new_df = pd.concat([region, country, Channel, Item, Priority, Date1, Date, df], axis = 1)

new_df

new_df = new_df.drop({'Region', 'Country', 'Sales Channel', 'Order Date', 'Item Type', 'Ship Date', 'Order Priority'}, axis = 1)

new_df.head(5)

X = new_df.drop('Total Profit', axis = 1)
y = new_df[['Total Profit']]

print(X.shape)
print(y.shape)

Scaler = MinMaxScaler()
X_scaled = Scaler.fit_transform(X)
y_scaled = Scaler.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size = 0.2)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(units = 128, activation = 'relu', input_shape = (308,)))
model.add(tf.keras.layers.Dense(units = 64, activation = 'relu'))
model.add(tf.keras.layers.Dense(units = 64, activation = 'relu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))
model.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))
model.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(units = 8, activation = 'relu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(units = 4, activation = 'relu'))
model.add(tf.keras.layers.Dense(units = 1, activation  = 'linear'))
model.summary()

keras.utils.plot_model(model, to_file='png', show_shapes=True)

model.compile(optimizer = 'Adam', loss = 'mean_squared_error')
from keras.callbacks import EarlyStopping
es = EarlyStopping(patience = 2, monitor = 'val_loss')
model.fit(X_train, y_train, epochs = 25, batch_size = 10, validation_data = (X_test, y_test), callbacks = [es])

hist = model.history.history
h = pd.DataFrame(hist)
h.plot()

y_predict = model.predict(X_test)
  y_predict

plt.plot(y_test,y_predict, '^', color = 'r')
plt.xlabel('y_test')
plt.ylabel('y_predict')

y_predict_original = Scaler.inverse_transform(y_predict)
y_test_original = Scaler.inverse_transform(y_test)
plt.plot(y_test_original,y_predict_original,'^',color = 'b')
plt.xlabel('model_predictions')
plt.ylabel('true_values')

k = X_test.shape
k
n = len(X_test)
print('\n')
n

from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
from math import sqrt
RMSE = float(format(np.sqrt(mean_squared_error(y_test_original,y_predict_original)), '0.3f'))
print(RMSE)

MSE = mean_squared_error(y_test_original,y_predict_original)
print(MSE)

MAE = mean_absolute_error(y_test_original,y_predict_original)
print(MAE)

r2 = r2_score(y_test_original,y_predict_original)
print(r2)

model.save("Predictor.h5")

